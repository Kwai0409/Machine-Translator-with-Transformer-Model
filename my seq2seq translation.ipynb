{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iRb6tIGlq3Af","executionInfo":{"status":"ok","timestamp":1687407331042,"user_tz":-480,"elapsed":27315,"user":{"displayName":"kianyooou gan","userId":"08554226229202021090"}},"outputId":"b05ba5bd-e8be-4609-b902-07263eecfa42"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["cd \"/content/gdrive/My Drive/Sequential_model/my_machine_translator\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mu_2dOVrq2xt","executionInfo":{"status":"ok","timestamp":1687407332612,"user_tz":-480,"elapsed":1577,"user":{"displayName":"kianyooou gan","userId":"08554226229202021090"}},"outputId":"41e6a739-940c-49e9-ca5b-1f37f7ebcf2b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/My Drive/Sequential_model/my_machine_translator\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"2dTAX-yjpvPM","executionInfo":{"status":"ok","timestamp":1687407337606,"user_tz":-480,"elapsed":4998,"user":{"displayName":"kianyooou gan","userId":"08554226229202021090"}}},"outputs":[],"source":["from __future__ import unicode_literals, print_function, division\n","from io import open\n","import unicodedata\n","import re\n","import random\n","\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","\n","import numpy as np\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","source":["\"\"\"\n","Ref:\n","https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n","https://pytorch.org/tutorials/beginner/translation_transformer.html\n","Download the data from https://download.pytorch.org/tutorial/data.zip\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"qDM_LG5L9pmS","executionInfo":{"status":"ok","timestamp":1687407337607,"user_tz":-480,"elapsed":41,"user":{"displayName":"kianyooou gan","userId":"08554226229202021090"}},"outputId":"dbd70f74-1fc1-41de-d4d5-e999afeeb321"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nRef: \\nhttps://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\\nhttps://pytorch.org/tutorials/beginner/translation_transformer.html\\nDownload the data from https://download.pytorch.org/tutorial/data.zip\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"code","execution_count":5,"metadata":{"id":"CeXoTvL_pvPQ","executionInfo":{"status":"ok","timestamp":1687407337608,"user_tz":-480,"elapsed":28,"user":{"displayName":"kianyooou gan","userId":"08554226229202021090"}}},"outputs":[],"source":["SOS_token = 1\n","EOS_token = 2\n","PAD_token = 0\n","\n","class Lang:\n","    def __init__(self, name):\n","        self.name = name\n","        self.word2index = {\"<PAD>\":0, \"<SOS>\":1, \"<EOS>\": 2}\n","        self.word2count = {\"<PAD>\":1, \"<SOS>\":1, \"<EOS>\": 1}\n","        self.index2word = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\"}\n","        self.n_words = 3  # Count PAD, SOS and EOS\n","\n","    def addSentence(self, sentence):\n","        for word in sentence.split(' '):\n","            self.addWord(word)\n","\n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.n_words\n","            self.word2count[word] = 1\n","            self.index2word[self.n_words] = word\n","            self.n_words += 1\n","        else:\n","            self.word2count[word] += 1"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"UqxEP-9HpvPS","executionInfo":{"status":"ok","timestamp":1687407337609,"user_tz":-480,"elapsed":29,"user":{"displayName":"kianyooou gan","userId":"08554226229202021090"}},"colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"0ed0a970-1255-4352-860c-fd0736f5a9dd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\ns = re.sub(r\"([.!?])\", r\" \\x01\", s):\\n    Input string: Hello! How are you? I\\'m fine.\\n    Output string: Hello ! How are you ? I\\'m fine .\\n\\ns = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s):\\n    Input string: Hello123! How are you? I\\'m fine.\\n    Output string: Hello ! How are you ? I m fine .\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}],"source":["# ref: https://stackoverflow.com/a/518232/2809427\n","# The files are all in Unicode, to simplify we will turn Unicode characters to ASCII, make everything lowercase, and trim most punctuation.\n","# Turn a Unicode string to plain ASCII\n","def unicodeToAscii(s):\n","    return ''.join(\n","        c for c in unicodedata.normalize('NFD', s)\n","        if unicodedata.category(c) != 'Mn'\n","    )\n","\n","\"\"\"\n","output_string = unicodeToAscii(\"Café au Lait\")\n","    Input string: Café au Lait\n","    Output string: Cafe au Lait\n","\"\"\"\n","\n","# Lowercase, trim, and remove non-letter characters\n","def normalizeString(s):\n","    s = unicodeToAscii(s.lower().strip())\n","    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n","    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n","    return s.strip()\n","\n","\"\"\"\n","s = re.sub(r\"([.!?])\", r\" \\1\", s):\n","    Input string: Hello! How are you? I'm fine.\n","    Output string: Hello ! How are you ? I'm fine .\n","\n","s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s):\n","    Input string: Hello123! How are you? I'm fine.\n","    Output string: Hello ! How are you ? I m fine .\n","\"\"\""]},{"cell_type":"code","execution_count":7,"metadata":{"id":"MqVacQG3pvPT","executionInfo":{"status":"ok","timestamp":1687407337610,"user_tz":-480,"elapsed":29,"user":{"displayName":"kianyooou gan","userId":"08554226229202021090"}}},"outputs":[],"source":["def readLangs(lang1, lang2, reverse=False):\n","    print(\"Reading lines...\")\n","\n","    # Read the file and split into lines\n","    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n","        read().strip().split('\\n')\n","\n","    # Split every line into pairs and normalize\n","    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n","\n","    # Reverse pairs, make Lang instances\n","    if reverse:\n","        pairs = [list(reversed(p)) for p in pairs]\n","        input_lang = Lang(lang2)\n","        output_lang = Lang(lang1)\n","    else:\n","        input_lang = Lang(lang1)\n","        output_lang = Lang(lang2)\n","\n","    return input_lang, output_lang, pairs"]},{"cell_type":"markdown","metadata":{"id":"mdiX4NofpvPU"},"source":["Since there are a *lot* of example sentences and we want to train\n","something quickly, we'll trim the data set to only relatively short and\n","simple sentences. Here the maximum length is 10 words (that includes\n","ending punctuation) and we're filtering to sentences that translate to\n","the form \"I am\" or \"He is\" etc. (accounting for apostrophes replaced\n","earlier).\n","\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"VE9oI79lpvPU","executionInfo":{"status":"ok","timestamp":1687407337610,"user_tz":-480,"elapsed":28,"user":{"displayName":"kianyooou gan","userId":"08554226229202021090"}}},"outputs":[],"source":["MAX_LENGTH = 10\n","\n","eng_prefixes = (\n","    \"i am \", \"i m \",\n","    \"he is\", \"he s \",\n","    \"she is\", \"she s \",\n","    \"you are\", \"you re \",\n","    \"we are\", \"we re \",\n","    \"they are\", \"they re \"\n",")\n","\n","def filterPair(p):\n","    return len(p[0].split(' ')) < MAX_LENGTH and \\\n","        len(p[1].split(' ')) < MAX_LENGTH and \\\n","        p[1].startswith(eng_prefixes)\n","\n","\n","def filterPairs(pairs):\n","    return [pair for pair in pairs if filterPair(pair)]"]},{"cell_type":"markdown","metadata":{"id":"C3pKjmqDpvPV"},"source":["The full process for preparing the data is:\n","\n","-  Read text file and split into lines, split lines into pairs\n","-  Normalize text, filter by length and content\n","-  Make word lists from sentences in pairs\n","\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"gUIQPGpVpvPV","outputId":"0e515d67-c3ee-4821-f945-06489ec493e3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687407342175,"user_tz":-480,"elapsed":4593,"user":{"displayName":"kianyooou gan","userId":"08554226229202021090"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading lines...\n","Read 135842 sentence pairs\n","Trimmed to 11445 sentence pairs\n","Counting words...\n","Counted words:\n","fra 4602\n","eng 2992\n","['il ne compte pas au nombre de mes amis', 'he is no friend of mine']\n"]}],"source":["def prepareData(lang1, lang2, reverse=False):\n","    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n","    print(\"Read %s sentence pairs\" % len(pairs))\n","    pairs = filterPairs(pairs)\n","    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n","    print(\"Counting words...\")\n","    for pair in pairs:\n","        input_lang.addSentence(pair[0])\n","        output_lang.addSentence(pair[1])\n","    print(\"Counted words:\")\n","    print(input_lang.name, input_lang.n_words)\n","    print(output_lang.name, output_lang.n_words)\n","    return input_lang, output_lang, pairs\n","\n","input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n","print(random.choice(pairs))"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"A0TGvsPBpvPZ","executionInfo":{"status":"ok","timestamp":1687407342176,"user_tz":-480,"elapsed":11,"user":{"displayName":"kianyooou gan","userId":"08554226229202021090"}}},"outputs":[],"source":["def indexesFromSentence(lang, sentence):\n","    return [lang.word2index[word] for word in sentence.split(' ')]\n","\n","def tensorFromSentence(lang, sentence):\n","    indexes = indexesFromSentence(lang, sentence)\n","    indexes.insert(0, SOS_token)\n","    indexes.append(EOS_token)\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1) #(1,t)\n","\n","def tensorsFromPair(pair):\n","    input_tensor = tensorFromSentence(input_lang, pair[0])\n","    target_tensor = tensorFromSentence(output_lang, pair[1])\n","    return (input_tensor, target_tensor)\n","\n","def get_dataloader(batch_size):\n","    #SOS_token = 0\n","    #EOS_token = 1\n","    input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n","\n","    \"\"\"load all data (indexs) to train_data\"\"\"\n","    n = len(pairs)\n","    input_ids = np.zeros((n, MAX_LENGTH+1), dtype=np.int32) #max word = 9, +<SOS> <EOS>\n","    target_ids = np.zeros((n, MAX_LENGTH+1), dtype=np.int32)\n","\n","    for idx, (inp, tgt) in enumerate(pairs):\n","        #Sentence to indexs\n","        inp_ids = indexesFromSentence(input_lang, inp)\n","        tgt_ids = indexesFromSentence(output_lang, tgt)\n","        #add <SOS> index\n","        inp_ids.insert(0, SOS_token)\n","        tgt_ids.insert(0, SOS_token)\n","        #add <EOS> index\n","        inp_ids.append(EOS_token)\n","        tgt_ids.append(EOS_token)\n","        input_ids[idx, :len(inp_ids)] = inp_ids #inp_ids = <This> <is> <example> <sentence> <EOS> <SOS> <SOS> .... <SOS>\n","        target_ids[idx, :len(tgt_ids)] = tgt_ids\n","\n","    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n","                               torch.LongTensor(target_ids).to(device))\n","\n","    train_sampler = RandomSampler(train_data)\n","    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","    return input_lang, output_lang, train_dataloader"]},{"cell_type":"code","source":["input_lang, output_lang, train_dataloader = get_dataloader(2)\n","for inp, tgt in train_dataloader:\n","    print(tgt)\n","    indexs = tgt[0].tolist()\n","    print(\" \".join([output_lang.index2word[idx] for idx in indexs]))\n","    indexs = tgt[1].tolist()\n","    print(\" \".join([output_lang.index2word[idx] for idx in indexs]))\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"voGs2DThuybn","executionInfo":{"status":"ok","timestamp":1687407353965,"user_tz":-480,"elapsed":11798,"user":{"displayName":"kianyooou gan","userId":"08554226229202021090"}},"outputId":"ce1a41a2-59a4-455d-cbbe-be023d2e53d3"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading lines...\n","Read 135842 sentence pairs\n","Trimmed to 11445 sentence pairs\n","Counting words...\n","Counted words:\n","fra 4602\n","eng 2992\n","tensor([[   1,    3,    4,  147, 2333,  378,  532, 1663,    2,    0,    0],\n","        [   1,  129,   78,   42,  841,  469,    2,    0,    0,    0,    0]],\n","       device='cuda:0')\n","<SOS> i m not comparing tom to mary <EOS> <PAD> <PAD>\n","<SOS> you re a wonderful friend <EOS> <PAD> <PAD> <PAD> <PAD>\n"]}]},{"cell_type":"markdown","source":["----\n","# Model"],"metadata":{"id":"_38JPHfFyHpi"}},{"cell_type":"code","source":["#ref: https://pytorch.org/tutorials/beginner/translation_transformer.html\n","\n","from torch import Tensor\n","import torch\n","import torch.nn as nn\n","from torch.nn import Transformer\n","import math\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, emb_size, dropout, maxlen = 5000):\n","        super(PositionalEncoding, self).__init__()\n","        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n","        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n","        pos_embedding = torch.zeros((maxlen, emb_size))\n","        pos_embedding[:, 0::2] = torch.sin(pos * den)\n","        pos_embedding[:, 1::2] = torch.cos(pos * den)\n","        pos_embedding = pos_embedding.unsqueeze(0) #(b=1, maxlen=seq_len, emb_size=d_model)\n","\n","        self.dropout = nn.Dropout(dropout)\n","        self.register_buffer('pos_embedding', pos_embedding)\n","\n","    def forward(self, token_embedding):\n","        #token_embedding (b,t_src,c) / (b,t_tgt,c)\n","        seq_len = token_embedding.size(1)\n","        return self.dropout(token_embedding + self.pos_embedding[:,:seq_len]) #(b,t_src,c) + (b:1,t_src,c)\n","\n","# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n","class TokenEmbedding(nn.Module):\n","    def __init__(self, vocab_size: int, emb_size):\n","        super(TokenEmbedding, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, emb_size)\n","        self.emb_size = emb_size\n","\n","    def forward(self, tokens: Tensor):\n","        #tokens (b,t_src) / (b,t_tgt) dtype=torch.int64\n","        return self.embedding(tokens.long()) * math.sqrt(self.emb_size) #self.embedding(tokens.long()) (b,t_src) / (b,t_tgt)\n","\n","# Seq2Seq Network\n","class Seq2SeqTransformer(nn.Module):\n","    def __init__(self, num_encoder_layers, num_decoder_layers,\n","                 emb_size, nhead, src_vocab_size, tgt_vocab_size,\n","                 dim_feedforward = 512, dropout = 0.1):\n","        super(Seq2SeqTransformer, self).__init__()\n","        self.transformer = Transformer(d_model=emb_size, nhead=nhead,\n","                                       num_encoder_layers=num_encoder_layers, num_decoder_layers=num_decoder_layers,\n","                                       dim_feedforward=dim_feedforward, dropout=dropout,\n","                                       batch_first=True)\n","        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n","        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n","        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n","        self.positional_encoding = PositionalEncoding(emb_size, dropout=dropout)\n","\n","    def forward(self, src, trg, src_mask, tgt_mask,\n","                src_padding_mask, tgt_padding_mask, memory_key_padding_mask):\n","        src_emb = self.positional_encoding(self.src_tok_emb(src))\n","        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n","        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n","                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n","\n","        #outs = (b, t_tgt, c)\n","        logits = self.generator(outs)\n","        #logits = (b, t_tgt, vocab)\n","        return logits\n","\n","    def encode(self, src, src_mask):\n","        return self.transformer.encoder(self.positional_encoding(\n","                            self.src_tok_emb(src)), src_mask)\n","\n","    def decode(self, tgt, memory, tgt_mask):\n","        return self.transformer.decoder(self.positional_encoding(\n","                          self.tgt_tok_emb(tgt)), memory,\n","                          tgt_mask)"],"metadata":{"id":"JOsTTtS7zvVn","executionInfo":{"status":"ok","timestamp":1687407353966,"user_tz":-480,"elapsed":19,"user":{"displayName":"kianyooou gan","userId":"08554226229202021090"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def generate_square_subsequent_mask(size):\n","    #size = t_tgt\n","    mask = (torch.triu(torch.ones((size, size), device=device)) == 1).transpose(0, 1)\n","    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n","    #mask (t_tgt, t_tgt)\n","    return mask\n","\n","\n","def create_mask(src, tgt):\n","    #src (b,t_src)\n","    #tgt (b,t_tgt)\n","    src_seq_len = src.shape[1]\n","    tgt_seq_len = tgt.shape[1]\n","\n","    tgt_mask = generate_square_subsequent_mask(tgt_seq_len) #tgt_mask(t_tgt, t_tgt)\n","    src_mask = torch.zeros((src_seq_len, src_seq_len), device=device).type(torch.bool) #src_mask(t_src,t_src)\n","\n","    src_padding_mask = (src == PAD_token) #src_padding_mask (b,t_src)\n","    tgt_padding_mask = (tgt == PAD_token) #tgt_padding_mask(b,t_tgt)\n","\n","    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"],"metadata":{"id":"jrskIeWe3XGR","executionInfo":{"status":"ok","timestamp":1687407353967,"user_tz":-480,"elapsed":19,"user":{"displayName":"kianyooou gan","userId":"08554226229202021090"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(0)\n","\n","SRC_VOCAB_SIZE = input_lang.n_words\n","TGT_VOCAB_SIZE = output_lang.n_words\n","EMB_SIZE = 512 #for embedding & transformer\n","NHEAD = 8\n","FFN_HID_DIM = 512 #for fc layer\n","NUM_ENCODER_LAYERS = 3\n","NUM_DECODER_LAYERS = 3\n","\n","model = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE, NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n","model = model.to(device)\n","\n","for p in model.parameters():\n","    if p.dim() > 1:\n","        nn.init.xavier_uniform_(p)\n","\n","loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_token)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"],"metadata":{"id":"lw1gar063akn","executionInfo":{"status":"ok","timestamp":1687405746575,"user_tz":-480,"elapsed":8,"user":{"displayName":"kianyooou gan","userId":"08554226229202021090"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","execution_count":47,"metadata":{"id":"U5t_O2rkpvPa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687406257025,"user_tz":-480,"elapsed":488550,"user":{"displayName":"kianyooou gan","userId":"08554226229202021090"}},"outputId":"2015fcfa-bc3c-45bf-d1c1-4089bc24213a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading lines...\n","Read 135842 sentence pairs\n","Trimmed to 11445 sentence pairs\n","Counting words...\n","Counted words:\n","fra 4602\n","eng 2992\n","Epoch: 1, Train loss: 3.889 Epoch time = 5.680s\n","Epoch: 2, Train loss: 2.689 Epoch time = 10.686s\n","Epoch: 3, Train loss: 2.221 Epoch time = 5.737s\n","Epoch: 4, Train loss: 1.892 Epoch time = 7.001s\n","Epoch: 5, Train loss: 1.634 Epoch time = 6.378s\n","Epoch: 6, Train loss: 1.419 Epoch time = 6.492s\n","Epoch: 7, Train loss: 1.236 Epoch time = 6.262s\n","Epoch: 8, Train loss: 1.082 Epoch time = 6.510s\n","Epoch: 9, Train loss: 0.946 Epoch time = 5.910s\n","Epoch: 10, Train loss: 0.832 Epoch time = 5.878s\n","Epoch: 11, Train loss: 0.735 Epoch time = 5.939s\n","Epoch: 12, Train loss: 0.642 Epoch time = 5.883s\n","Epoch: 13, Train loss: 0.567 Epoch time = 6.725s\n","Epoch: 14, Train loss: 0.500 Epoch time = 6.653s\n","Epoch: 15, Train loss: 0.440 Epoch time = 6.941s\n","Epoch: 16, Train loss: 0.392 Epoch time = 5.719s\n","Epoch: 17, Train loss: 0.343 Epoch time = 6.408s\n","Epoch: 18, Train loss: 0.303 Epoch time = 5.994s\n","Epoch: 19, Train loss: 0.270 Epoch time = 6.143s\n","Epoch: 20, Train loss: 0.242 Epoch time = 5.730s\n","Epoch: 21, Train loss: 0.213 Epoch time = 5.824s\n","Epoch: 22, Train loss: 0.193 Epoch time = 6.464s\n","Epoch: 23, Train loss: 0.173 Epoch time = 5.668s\n","Epoch: 24, Train loss: 0.156 Epoch time = 6.080s\n","Epoch: 25, Train loss: 0.143 Epoch time = 5.663s\n","Epoch: 26, Train loss: 0.128 Epoch time = 6.066s\n","Epoch: 27, Train loss: 0.118 Epoch time = 5.709s\n","Epoch: 28, Train loss: 0.109 Epoch time = 5.968s\n","Epoch: 29, Train loss: 0.101 Epoch time = 5.840s\n","Epoch: 30, Train loss: 0.094 Epoch time = 5.720s\n","Epoch: 31, Train loss: 0.089 Epoch time = 6.379s\n","Epoch: 32, Train loss: 0.083 Epoch time = 5.685s\n","Epoch: 33, Train loss: 0.078 Epoch time = 6.052s\n","Epoch: 34, Train loss: 0.076 Epoch time = 5.663s\n","Epoch: 35, Train loss: 0.072 Epoch time = 5.942s\n","Epoch: 36, Train loss: 0.070 Epoch time = 5.832s\n","Epoch: 37, Train loss: 0.067 Epoch time = 6.121s\n","Epoch: 38, Train loss: 0.067 Epoch time = 5.995s\n","Epoch: 39, Train loss: 0.064 Epoch time = 5.700s\n","Epoch: 40, Train loss: 0.062 Epoch time = 6.068s\n","Epoch: 41, Train loss: 0.061 Epoch time = 5.717s\n","Epoch: 42, Train loss: 0.060 Epoch time = 6.049s\n","Epoch: 43, Train loss: 0.057 Epoch time = 5.695s\n","Epoch: 44, Train loss: 0.056 Epoch time = 5.947s\n","Epoch: 45, Train loss: 0.054 Epoch time = 5.918s\n","Epoch: 46, Train loss: 0.054 Epoch time = 5.698s\n","Epoch: 47, Train loss: 0.053 Epoch time = 6.107s\n","Epoch: 48, Train loss: 0.052 Epoch time = 5.766s\n","Epoch: 49, Train loss: 0.051 Epoch time = 6.110s\n","Epoch: 50, Train loss: 0.051 Epoch time = 5.687s\n","Epoch: 51, Train loss: 0.050 Epoch time = 5.977s\n","Epoch: 52, Train loss: 0.048 Epoch time = 5.796s\n","Epoch: 53, Train loss: 0.048 Epoch time = 5.759s\n","Epoch: 54, Train loss: 0.047 Epoch time = 6.012s\n","Epoch: 55, Train loss: 0.046 Epoch time = 5.672s\n","Epoch: 56, Train loss: 0.045 Epoch time = 6.045s\n","Epoch: 57, Train loss: 0.045 Epoch time = 5.674s\n","Epoch: 58, Train loss: 0.045 Epoch time = 6.037s\n","Epoch: 59, Train loss: 0.044 Epoch time = 5.795s\n","Epoch: 60, Train loss: 0.044 Epoch time = 5.761s\n","Epoch: 61, Train loss: 0.043 Epoch time = 5.939s\n","Epoch: 62, Train loss: 0.042 Epoch time = 5.667s\n","Epoch: 63, Train loss: 0.044 Epoch time = 6.047s\n","Epoch: 64, Train loss: 0.041 Epoch time = 5.696s\n","Epoch: 65, Train loss: 0.043 Epoch time = 5.985s\n","Epoch: 66, Train loss: 0.041 Epoch time = 5.748s\n","Epoch: 67, Train loss: 0.040 Epoch time = 5.768s\n","Epoch: 68, Train loss: 0.041 Epoch time = 5.942s\n","Epoch: 69, Train loss: 0.039 Epoch time = 5.701s\n","Epoch: 70, Train loss: 0.039 Epoch time = 6.097s\n","Epoch: 71, Train loss: 0.040 Epoch time = 5.860s\n","Epoch: 72, Train loss: 0.039 Epoch time = 6.214s\n","Epoch: 73, Train loss: 0.039 Epoch time = 5.646s\n","Epoch: 74, Train loss: 0.037 Epoch time = 5.851s\n","Epoch: 75, Train loss: 0.040 Epoch time = 5.846s\n","Epoch: 76, Train loss: 0.037 Epoch time = 5.653s\n","Epoch: 77, Train loss: 0.037 Epoch time = 6.009s\n","Epoch: 78, Train loss: 0.038 Epoch time = 5.671s\n","Epoch: 79, Train loss: 0.036 Epoch time = 6.108s\n","Epoch: 80, Train loss: 0.038 Epoch time = 5.676s\n"]}],"source":["from torch.utils.data import DataLoader\n","\n","def train_epoch(model, train_dataloader, optimizer):\n","    model.train()\n","    losses = 0\n","    count = 0\n","\n","    for src, tgt in train_dataloader:\n","        #src (b, t_src:11)\n","        #tgt (b, t_tgt:11)\n","        src = src.to(device)\n","        tgt = tgt.to(device)\n","\n","        tgt_input = tgt[:, :-1] #remove 1 last token, because we will remove <SOS> later\n","        #tgt_input (b, t_tgt:10)\n","\n","        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n","\n","        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n","        #logits (b, t_tgt:10, vocab_size)\n","\n","        optimizer.zero_grad()\n","\n","        expect_tgt = tgt[:, 1:] #remove <SOS>\n","        #expect_tgt (b, t_tgt:10)\n","        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), expect_tgt.reshape(-1))\n","        loss.backward()\n","\n","        optimizer.step()\n","        losses += loss.item()\n","        count += 1\n","\n","    return losses / count\n","\n","from timeit import default_timer as timer\n","NUM_EPOCHS = 80\n","input_lang, output_lang, train_dataloader = get_dataloader(64)\n","for epoch in range(1, NUM_EPOCHS+1):\n","    start_time = timer()\n","    train_loss = train_epoch(model, train_dataloader, optimizer)\n","    end_time = timer()\n","    #val_loss = evaluate(model)\n","    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f} \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n","    #print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n"]},{"cell_type":"code","source":["torch.save(model, \"myTranslator.pt\")"],"metadata":{"id":"OgPX8CgGQQ_5","executionInfo":{"status":"ok","timestamp":1687406332721,"user_tz":-480,"elapsed":590,"user":{"displayName":"kianyooou gan","userId":"08554226229202021090"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["def evaluate(model, val_dataloader):\n","    model.eval()\n","    losses = 0\n","    count = 0\n","\n","    for src, tgt in val_dataloader:\n","        #tgt (b,t)\n","        src = src.to(device)\n","        tgt = tgt.to(device)\n","\n","        tgt_input = tgt[:, :-1] #last token\n","\n","        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n","\n","        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n","\n","        tgt_out = tgt[1:, :] #remove <SOS>\n","        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n","        losses += loss.item()\n","        count += 1\n","\n","    return losses / count"],"metadata":{"id":"jvi9teFGKXy8","executionInfo":{"status":"ok","timestamp":1687405751326,"user_tz":-480,"elapsed":16,"user":{"displayName":"kianyooou gan","userId":"08554226229202021090"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["# function to generate output sequence using greedy algorithm\n","def greedy_decode(model, src, src_mask, max_len, start_symbol):\n","    src = src.to(device)\n","    src_mask = src_mask.to(device)\n","\n","    memory = model.encode(src, src_mask)\n","    #(1,t,embed_size)\n","    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(device)\n","    #ys (1,1)\n","    for i in range(max_len-1):\n","        memory = memory.to(device)\n","        #ys (1, t:1+i)\n","        tgt_mask = (generate_square_subsequent_mask(ys.size(1))\n","                    .type(torch.bool)).to(device)\n","        #tgt_mask (t, t)\n","        out = model.decode(ys, memory, tgt_mask) #out (b,t,embed_size)\n","        prob = model.generator(out[:, -1]) #prob (b=1,vocab_size)\n","        _, next_word = torch.max(prob, dim=1)\n","        next_word = next_word.item()\n","        ys = torch.cat([ys,\n","                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n","        if next_word == EOS_token:\n","            break\n","    return ys\n","\n","\n","# actual function to translate input sentence into target language\n","def translate(model, src_sentence: str):\n","    model.eval()\n","    src = tensorFromSentence(input_lang, src_sentence) #sentence to indexs\n","    #src (1, t)\n","    num_tokens = src.shape[1]\n","    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n","    tgt_tokens = greedy_decode(model,  src, src_mask, max_len=num_tokens + 5, start_symbol=SOS_token).flatten()\n","    return \" \".join(output_lang.index2word[token] for token in list(tgt_tokens.cpu().numpy()))\n","    #return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"],"metadata":{"id":"AgKkoDjd3s8f","executionInfo":{"status":"ok","timestamp":1687407393841,"user_tz":-480,"elapsed":4,"user":{"displayName":"kianyooou gan","userId":"08554226229202021090"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["myModel = torch.load('myTranslator.pt')"],"metadata":{"id":"NYBlZsjxTeyv","executionInfo":{"status":"ok","timestamp":1687407354781,"user_tz":-480,"elapsed":832,"user":{"displayName":"kianyooou gan","userId":"08554226229202021090"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["for i in range(10):\n","    french, english = random.choice(pairs)\n","    print(f\"===== Example {i+1} =====\")\n","    print(\"French, X \\t=\", french)\n","    print(\"English, Y \\t=\", english)\n","    print(\"Predicted, Yhat =\", translate(myModel, french))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Ia5xXzISIVW","executionInfo":{"status":"ok","timestamp":1687407967730,"user_tz":-480,"elapsed":1041,"user":{"displayName":"kianyooou gan","userId":"08554226229202021090"}},"outputId":"6b7382c0-5597-4a56-8547-a393b7e08e3c"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["===== Example 1 =====\n","French, X \t= nous prenons l ascendant\n","English, Y \t= we re taking over\n","Predicted, Yhat = <SOS> we re taking over <EOS>\n","===== Example 2 =====\n","French, X \t= vous plaisantez bien sur\n","English, Y \t= you re joking of course\n","Predicted, Yhat = <SOS> you re joking of course <EOS>\n","===== Example 3 =====\n","French, X \t= vous commettez une grosse erreur\n","English, Y \t= you re making a big mistake\n","Predicted, Yhat = <SOS> you re making a big mistake <EOS>\n","===== Example 4 =====\n","French, X \t= je suis tres serieux\n","English, Y \t= i m very serious\n","Predicted, Yhat = <SOS> i m quite serious <EOS>\n","===== Example 5 =====\n","French, X \t= tu es bien plus jolie que dans mon souvenir\n","English, Y \t= you re much prettier than i remember\n","Predicted, Yhat = <SOS> you re much prettier than i remember <EOS>\n","===== Example 6 =====\n","French, X \t= c est bon pour moi pour l instant\n","English, Y \t= i m good for now\n","Predicted, Yhat = <SOS> i m good for now <EOS>\n","===== Example 7 =====\n","French, X \t= tu me fais marrer\n","English, Y \t= you re amusing\n","Predicted, Yhat = <SOS> you re amusing <EOS>\n","===== Example 8 =====\n","French, X \t= elle n est pas plus belle que sa mere\n","English, Y \t= she s not prettier than her mother\n","Predicted, Yhat = <SOS> she s not prettier than her mother <EOS>\n","===== Example 9 =====\n","French, X \t= je me casse\n","English, Y \t= i m hitting the road\n","Predicted, Yhat = <SOS> i m hitting the road <EOS>\n","===== Example 10 =====\n","French, X \t= ils sont trop gras\n","English, Y \t= they re too fat\n","Predicted, Yhat = <SOS> they re too fat <EOS>\n"]}]},{"cell_type":"code","source":["print(translate(model, \"je suis enchantee d etre ici\"))"],"metadata":{"id":"v7_U9kqi3utB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(translate(model, \"je ne suis pas encore prete\")) #je commence a peine"],"metadata":{"id":"dL1HlbqjVJXn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(translate(model, \"je commence a peine\"))"],"metadata":{"id":"XF7yaC2QcEC4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"j7thzVsjddnN","executionInfo":{"status":"ok","timestamp":1687405751329,"user_tz":-480,"elapsed":10,"user":{"displayName":"kianyooou gan","userId":"08554226229202021090"}}},"execution_count":46,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}